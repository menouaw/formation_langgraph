{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Bases\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Dans `first_steps.py`, on a construit un graphe simple avec des noeuds, des arêtes régulières et conditionnelles.\n",
    "\n",
    "Construisons maintenant une chaîne simple qui combine quatre concepts d'une app conversationnel.\n",
    "\n",
    "- Utiliser les [messages](https://docs.langchain.com/oss/python/langchain/messages) comme état du graphe\n",
    "- Utiliser des [modèles conversationnels](https://docs.langchain.com/oss/python/integrations/chat) dans les noeuds du graphe\n",
    "- [Lier des outils](https://docs.langchain.com/oss/python/langchain/models#tool-calling) à notre modèle conversationnel\n",
    "- [Exécuter des appels d'outils](https://docs.langchain.com/oss/python/langchain/models#tool-execution-loop) dans les noeuds du graphe\n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:50.371533Z",
     "start_time": "2025-11-06T19:19:45.160141Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages\n",
    "\n",
    "Les modèles conversationnels peuvent utiliser des [messages](https://docs.langchain.com/oss/python/langchain/messages), dont le type diffère:\n",
    "- `HumanMessage`: utilisateur\n",
    "- `AIMessage`: modèle conversationnel\n",
    "- `SystemMessage`: instructions sur le comportement du modèle\n",
    "- `ToolMessage`: réponse d'appel à l'outil\n",
    "\n",
    "Chaque message peut contenir plusieurs éléments:\n",
    "\n",
    "- `content`: le contenu du message\n",
    "- `name`: optionnellement, l'auteur du message\n",
    "- `response_metadata`: optionnellement, des métadonnées liées à la réponse (au format d'un liste associative)"
   ]
  },
  {
   "cell_type": "code",
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:50.496708Z",
     "start_time": "2025-11-06T19:19:50.456079Z"
    }
   },
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"Alors tu cherches à comprendre les tests de performance?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Oui, c'est ça.\",name=\"John\"))\n",
    "messages.append(AIMessage(content=f\"Bien, que veux-tu savoir en particulier?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"Je veux savoir ce que l'IA apporte aux tests de performances.\", name=\"John\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Alors tu cherches à comprendre les tests de performance?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: John\n",
      "\n",
      "Oui, c'est ça.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Bien, que veux-tu savoir en particulier?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "Name: John\n",
      "\n",
      "Je veux savoir ce que l'IA apporte aux tests de performances.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Modèles conversationnels\n",
    "\n",
    "On peut intégrer [plusieurs fournisseurs de modèles](https://docs.langchain.com/oss/python/integrations/chat) mais cette formation utilisera OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:50.645202Z",
     "start_time": "2025-11-06T19:19:50.623644Z"
    }
   },
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": "Continuons avec notre exemple."
  },
  {
   "cell_type": "code",
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:59.104020Z",
     "start_time": "2025-11-06T19:19:50.681597Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:59.347568Z",
     "start_time": "2025-11-06T19:19:59.331498Z"
    }
   },
   "source": [
    "result"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"L'intelligence artificielle (IA) apporte plusieurs avantages significatifs aux tests de performance, en améliorant leur efficacité, leur précision et leur adaptabilité. Voici quelques manières clés dont l'IA influe sur les tests de performance :\\n\\n1. **Automatisation Intelligente** : L'IA permet l'automatisation des tests de performance à un niveau très avancé. Les algorithmes d'apprentissage automatique peuvent automatiser la création, l'exécution et l'analyse des tests, réduisant ainsi le besoin d'une intervention humaine constante.\\n\\n2. **Analyse Prédictive** : Les capacités d'analyse prédictive de l'IA peuvent être utilisées pour anticiper les problèmes de performance avant qu'ils ne surviennent. L'IA peut analyser des données historiques pour identifier des tendances et des schémas qui pourraient mener à des problèmes, permettant ainsi de les traiter proactivement.\\n\\n3. **Détection Anomalies** : L'IA est efficace pour détecter les anomalies dans le comportement des applications lors des tests de performance. Cela signifie qu'elle peut identifier des performances anormales ou des défaillances potentielles qui pourraient être négligées par les méthodes manuelles.\\n\\n4. **Optimisation Continues** : Grâce à l'IA, il est possible de réaliser une optimisation continue des applications. Les outils basés sur l'IA peuvent proposer des améliorations de la performance en temps réel, adaptes à l'évolution des besoins et des environnements de charge.\\n\\n5. **Tests Scalables** : L'IA peut faciliter la création de tests de charge et de stress qui sont à la fois réalistes et scalables. Cela est particulièrement utile pour simuler des millions d'interactions utilisateur, en testant comment les systèmes se comportent sous une forte pression.\\n\\n6. **Réduction du Temps et des Coûts** : En automatisant bon nombre de tâches et en fournissant une analyse plus rapide et plus précise, l'IA peut réduire le temps et les coûts associés aux tests de performance, tout en augmentant la couverture des tests.\\n\\nEn intégrant l'IA dans les tests de performance, les organisations peuvent obtenir des tests plus réactifs, adaptatifs et fiables, ce qui est essentiel pour répondre aux exigences croissantes des utilisateurs et aux environnements technologiques en évolution rapide.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 472, 'prompt_tokens': 67, 'total_tokens': 539, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CYzoOyWCYGMS2ais2ClU6KpJXkoJ1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--bacf6801-1a76-4859-b78e-cc1777da7118-0', usage_metadata={'input_tokens': 67, 'output_tokens': 472, 'total_tokens': 539, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:59.443952Z",
     "start_time": "2025-11-06T19:19:59.423326Z"
    }
   },
   "source": [
    "result.response_metadata"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 472,\n",
       "  'prompt_tokens': 67,\n",
       "  'total_tokens': 539,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-4o-2024-08-06',\n",
       " 'system_fingerprint': 'fp_cbf1785567',\n",
       " 'id': 'chatcmpl-CYzoOyWCYGMS2ais2ClU6KpJXkoJ1',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Outils\n",
    "\n",
    "Les outils permettent au modèle d'interagir avec des systèmes externes (tels qu'une base de données, un calendrier ou une boîte mail).\n",
    "\n",
    "Le modèle choisira d'appeler un outil en fonction de l'entrée en langage naturel fournie par l'utilisateur et il renverra une sortie qui respecte le schéma de réponse de l'outil.\n",
    "\n",
    "[Nombreux fournisseurs prennent en charge l'appel d'outils](https://docs.langchain.com/oss/python/integrations/chat) et l'[interface d'appel d'outils](https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/) dans LangChain est simplifié pour.\n",
    "\n",
    "On utilise `ChatModel.bind_tools(function)` pour lier un outil au modèle.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "Prenons la multiplication comme outil."
  },
  {
   "cell_type": "code",
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:19:59.705252Z",
     "start_time": "2025-11-06T19:19:59.515890Z"
    }
   },
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplie a avec b?\n",
    "\n",
    "    Args:\n",
    "        a: entier\n",
    "        b: entier\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "L'appel d'outil contient des arguments spécifiques correspondant au schéma d'entrée de notre fonction ainsi que le nom de la fonction à appeler.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":8,\"b\":12}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.414130Z",
     "start_time": "2025-11-06T19:19:59.745374Z"
    }
   },
   "source": "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"Multiplie 8 par 12.\", name=\"John\")])",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.465047Z",
     "start_time": "2025-11-06T19:20:00.447633Z"
    }
   },
   "source": [
    "tool_call.tool_calls"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 8, 'b': 12},\n",
       "  'id': 'call_R3BhrmhvaeNFSdJ2Et1Hl2ww',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages comme état\n",
    "\n",
    "On peut maintenant utiliser les [messages](https://docs.langchain.com/oss/python/langchain/overview#messages) dans l'état de notre graphe.\n",
    "\n",
    "Définissons notre état: `MessagesState` comme un `TypedDict` avec une seule clef: `messages`, qui est une liste de messages."
   ]
  },
  {
   "cell_type": "code",
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.531886Z",
     "start_time": "2025-11-06T19:20:00.517878Z"
    }
   },
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Réducteurs\n",
    "\n",
    "Nous avons maintenant un petit problème !\n",
    "\n",
    "Comme mentionné, chaque nœud retournera une nouvelle valeur pour notre clef d'état `messages`.\n",
    "\n",
    "Mais, cette nouvelle valeur écrasera la valeur précédente de `messages` !\n",
    "\n",
    "Au fur et à mesure que notre graphe s'exécute, nous voulons **ajouter*- des messages à notre clef d'état `messages`.\n",
    "\n",
    "Nous pouvons utiliser des [fonctions réductrices](https://docs.langchain.com/oss/python/langgraph/graph-api#reducers) pour résoudre cela.\n",
    "\n",
    "Les réducteurs spécifient comment les mises à jour d'état sont effectuées.\n",
    "\n",
    "Si aucune fonction réductrice n'est spécifiée, il est supposé que les mises à jour de la clef doivent *l'écraser*, comme nous l'avons vu précédemment.\n",
    "\n",
    "Mais, pour ajouter des messages, nous pouvons utiliser le réducteur pré-construit `add_messages`.\n",
    "\n",
    "Cela garantit que tous les messages sont ajoutés à la liste existante de messages.\n",
    "\n",
    "Nous devons simplement annoter notre clef `messages` avec la fonction réductrice `add_messages` en tant que métadonnée."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.595844Z",
     "start_time": "2025-11-06T19:20:00.581272Z"
    }
   },
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "On utilisera généralement `MessagesState` car il est moins verbeux que la définition d'un `TypedDict` personnalisé. Il est défini par:\n",
    "- une clef unique `messages`\n",
    "- une liste d'objets `AnyMessage`\n",
    "- le réducteur `add_messages`"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.630692Z",
     "start_time": "2025-11-06T19:20:00.618700Z"
    }
   },
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Ajoutez des clefs supplémentaires au-delà de messages si nécessaire, qui est pré-construit\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": "Analysons le comportement de `add_messages`."
  },
  {
   "cell_type": "code",
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:00.683761Z",
     "start_time": "2025-11-06T19:20:00.660313Z"
    }
   },
   "source": [
    "# état initial\n",
    "initial_messages = [AIMessage(content=\"Bonjour, comment puis-je vous assister?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"Je cherche des informations au sujet de LangGraph.\", name=\"John\")\n",
    "                   ]\n",
    "\n",
    "# ajout d'un nouveau message\n",
    "new_message = AIMessage(content=\"Bien, que souhaites-tu savoir en particulier?\", name=\"Model\")\n",
    "\n",
    "# essai\n",
    "add_messages(initial_messages , new_message)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Bonjour, comment puis-je vous assister?', additional_kwargs={}, response_metadata={}, name='Model', id='bdcf6604-6513-47f3-9c06-1c5e25df6b0f'),\n",
       " HumanMessage(content='Je cherche des informations au sujet de LangGraph.', additional_kwargs={}, response_metadata={}, name='John', id='09d05c51-b96d-42f1-b74c-176188be635e'),\n",
       " AIMessage(content='Bien, que souhaites-tu savoir en particulier?', additional_kwargs={}, response_metadata={}, name='Model', id='4b40f85c-4ec0-4af7-a453-6a24c6252b0f')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Utilisation\n",
    "\n",
    "Maintenant, utilisons `MessagesState` avec un graphe."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:02.428823Z",
     "start_time": "2025-11-06T19:20:00.733779Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# noeud\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"]) ]}\n",
    "\n",
    "# construction du graphe\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# représentation\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": "Si nous fournissons `Bonjour!`, le LLM répond sans aucun appel d'outil."
  },
  {
   "cell_type": "code",
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:03.178440Z",
     "start_time": "2025-11-06T19:20:02.507707Z"
    }
   },
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Bonjour!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Bonjour!\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Bonjour! Comment puis-je vous aider aujourd'hui ?\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": "Le LLM choisit d'utiliser un outil lorsqu'il détermine que l'entrée ou la tâche nécessite la fonctionnalité fournie par cet outil."
  },
  {
   "cell_type": "code",
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T19:20:04.100213Z",
     "start_time": "2025-11-06T19:20:03.240198Z"
    }
   },
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiplie 8 par 12.\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Multiplie 8 par 12.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_3zekG2BqRehH3OYhfoedKsPX)\n",
      " Call ID: call_3zekG2BqRehH3OYhfoedKsPX\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: 12\n"
     ]
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
